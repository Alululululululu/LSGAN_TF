{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 얼마전에 나온 Least Squares Generative Adversarial Networks를 구현해봤습니다.\n",
    "# 복습할겸 한줄한줄 설명을 달아보겠습니다.\n",
    "\n",
    "# Tensorflow implementation of the paper \"Least Squares Generative Adversarial Networks\"\n",
    "# https://arxiv.org/abs/1611.04076\n",
    "# Coded by GunhoChoi 170305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 우선 필요한 라이브러리와 데이터를 불러옵니다.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 학습때 필요한 Hyperparameter를 설정해놓습니다.\n",
    "\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이미지 데이터와 제너레이터의 z를 받아올 placeholder를 생성해 놓습니다.\n",
    "# 그냥 불러오면 784개의 한줄짜리 데이터이기 때문에 28x28x1로 모양을 바꿔줍니다.\n",
    "# 또한 variable initializer도 설정해줍니다.\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "z_in = tf.placeholder(tf.float32, shape=[batch_size, 100])\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discriminator가 더 잘 학습되도록 그냥 relu 대신 leaky relu를 구현했습니다.\n",
    "# tf.maximum(x, a*x)로 하는 방법도 있지만 메모리를 두배로 쓰기 때문에 아래와 같이 구현했습니다.\n",
    "# 해당 issue가 텐서플로우 깃헙에 올라와 있는데 링크 첨부합니다.\n",
    "# https://github.com/tensorflow/tensorflow/issues/4079\n",
    "\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator를 만들어줍니다. \n",
    "# tf.variable_scope를 사용하면 나중에 제너레이터 부분만 업데이트하는데 편리합니다.\n",
    "# conv2d_transpose 대신 아래와 같이 conv2d -> reshape 를 사용한 이유는 아래 링크에 있습니다.\n",
    "# http://distill.pub/2016/deconv-checkerboard/ \n",
    "# 근데 텐서플로우 1.0에서 이 부분을 감안해서 짰는지는 확인 못했습니다.\n",
    "\n",
    "def generator(z):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\"):\n",
    "       \n",
    "        fc1 = tf.contrib.layers.fully_connected(inputs=z, num_outputs=7*7*128, activation_fn=tf.nn.relu, \\\n",
    "                                                normalizer_fn=tf.contrib.layers.batch_norm,\\\n",
    "                                                weights_initializer=initializer,scope=\"g_fc1\")\n",
    "        fc1 = tf.reshape(fc1, shape=[batch_size, 7, 7, 128])\n",
    "        conv1 = tf.contrib.layers.conv2d(fc1, num_outputs=4*64, kernel_size=5, stride=1, padding=\"SAME\",    \\\n",
    "                                        activation_fn=tf.nn.relu, normalizer_fn=tf.contrib.layers.batch_norm, \\\n",
    "                                        weights_initializer=initializer,scope=\"g_conv1\")\n",
    "        conv1 = tf.reshape(conv1, shape=[batch_size,14,14,64])\n",
    "        conv2 = tf.contrib.layers.conv2d(conv1, num_outputs=4*32, kernel_size=5, stride=1, padding=\"SAME\", \\\n",
    "                                        activation_fn=tf.nn.relu,normalizer_fn=tf.contrib.layers.batch_norm, \\\n",
    "                                        weights_initializer=initializer,scope=\"g_conv2\")\n",
    "\n",
    "        conv2 = tf.reshape(conv2, shape=[batch_size,28,28,32])\n",
    "        conv3 = tf.contrib.layers.conv2d(conv2, num_outputs=1, kernel_size=5, stride=1, padding=\"SAME\", \\\n",
    "                                        activation_fn=tf.nn.tanh,scope=\"g_conv3\")\n",
    "\n",
    "        return conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator도 만들어줍니다.\n",
    "# Variable reuse에 관한 설명은 아래 링크로 대신합니다.\n",
    "# https://www.tensorflow.org/programmers_guide/variable_scope\n",
    "\n",
    "def discriminator(tensor,reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\"):\n",
    "\n",
    "        conv1 = tf.contrib.layers.conv2d(inputs=tensor, num_outputs=32, kernel_size=5, stride=2, padding=\"SAME\", \\\n",
    "                                        reuse=reuse, activation_fn=lrelu,weights_initializer=initializer,scope=\"d_conv1\")\n",
    "        conv2 = tf.contrib.layers.conv2d(inputs=conv1, num_outputs=64, kernel_size=5, stride=2, padding=\"SAME\", \\\n",
    "                                        reuse=reuse, activation_fn=lrelu,normalizer_fn=tf.contrib.layers.batch_norm,\\\n",
    "                                        weights_initializer=initializer,scope=\"d_conv2\")\n",
    "        fc1 = tf.reshape(conv2, shape=[batch_size, 7*7*64])\n",
    "        fc1 = tf.contrib.layers.fully_connected(inputs=fc1, num_outputs=512,reuse=reuse, activation_fn=lrelu, \\\n",
    "                                                normalizer_fn=tf.contrib.layers.batch_norm, \\\n",
    "                                                weights_initializer=initializer,scope=\"d_fc1\")\n",
    "        fc2 = tf.contrib.layers.fully_connected(inputs=fc1, num_outputs=1, reuse=reuse, activation_fn=tf.nn.sigmoid,\\\n",
    "                                                weights_initializer=initializer,scope=\"d_fc2\")\n",
    "\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 학습을 시키기 위해서는 D(G(z))와 D(x)가 필요하기 때문에 아래처럼 그래프를 만들어줍니다.\n",
    "\n",
    "g_out = generator(z_in)\n",
    "d_out_fake = discriminator(g_out)\n",
    "d_out_real = discriminator(x_image,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss는 논문에 나온대로 구현합니다.\n",
    "\n",
    "disc_loss = tf.reduce_sum(tf.square(d_out_real-1) + tf.square(d_out_fake))/2\n",
    "gen_loss = tf.reduce_sum(tf.square(d_out_fake-1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 여기부터가 제가 좀 헷갈렸던 부분인데 gen_loss는 generator만 업데이트하고\n",
    "# disc_loss는 discriminator만 업데이트하도록 하기 위해서 \n",
    "# 각 name_scope에서 variable을 불러옵니다.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/GraphKeys\n",
    "# https://www.tensorflow.org/api_docs/python/tf/get_collection\n",
    "\n",
    "gen_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"generator\") \n",
    "dis_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"discriminator\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 그 다음엔 loss에 대한 해당 variable의 gradient를 구해 이를 업데이트 합니다.\n",
    "\n",
    "d_optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "g_optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "d_grads = d_optimizer.compute_gradients(disc_loss,dis_variables) \n",
    "g_grads = g_optimizer.compute_gradients(gen_loss,gen_variables) \n",
    "\n",
    "update_D = d_optimizer.apply_gradients(d_grads)\n",
    "update_G = g_optimizer.apply_gradients(g_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 / d_loss: 0.25470638275146484 / g_loss: 0.14624617993831635\n"
     ]
    }
   ],
   "source": [
    "# 위에 설정한 epoch만큼 반복하면서 다음 batch와 z를 생성해 feed_dict로 전달합니다.\n",
    "# 이때 discriminator 한번에 generator 한번으로 학습하면 generator가 학습을 포기하기 때문에\n",
    "# 적당한 비율로 돌려야하는데 보통은 연산 횟수에 맞춰 d:g=1:2로 한다고 합니다.\n",
    "# 저는 generator에게 더 많은 기회를 주기로 결정하여 이를 늘려서 학습하였습니다.\n",
    "# 그리고 변화를 시각적으로 확인하기 위해 10번마다 generator의 output을 저장했습니다. \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        z_input = np.random.uniform(0,1.0,size=[batch_size,100]).astype(np.float32)\n",
    "\n",
    "        _, d_loss = sess.run([update_D,disc_loss],feed_dict={x: batch[0], z_in: z_input})\n",
    "        \n",
    "        for j in range(4):\n",
    "            _, g_loss = sess.run([update_G,gen_loss],feed_dict={z_in: z_input})\n",
    "\n",
    "        print(\"i: {} / d_loss: {} / g_loss: {}\".format(i,np.sum(d_loss)/batch_size, np.sum(g_loss)/batch_size))\n",
    "\n",
    "        if i % 10 == 0:\n",
    "\n",
    "            gen_o = sess.run(g_out,feed_dict={z_in: z_input})\n",
    "            #result = plt.imshow(gen_o[0][:, :, 0], cmap=\"gray\")\n",
    "            plt.imsave(\"{}.png\".format(i),gen_o[0][:, :, 0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
